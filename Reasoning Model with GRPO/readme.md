# Reasoning Model with GRPO

This repository hosts a custom-built reasoning model powered by **LLama 3.1 8B** and enhanced using **GRPO (Guided Reinforcement with Preference Optimization)**. The model is fine-tuned for advanced reasoning tasks, designed to perform logical inference, multi-step deduction, and structured decision-making.

## ğŸ” Key Features

- **LLama 3.1 Backbone**: Utilizes the power of Metaâ€™s LLama 3.1 for high-quality language understanding.
- **GRPO Training**: Reinforcement-based preference optimization to guide reasoning performance.
- **Enhanced Reasoning**: Optimized for complex prompts, chain-of-thought reasoning, and preference-aligned outputs.

## ğŸ“¦ Contents

- `model/` â€” Model weights and configs (or links)
- `training/` â€” Scripts and GRPO config used for training
- `inference/` â€” Quick inference code and usage samples
- `examples/` â€” Reasoning test prompts and outputs

## ğŸš€ Usage

- Run the python script..
