# Reasoning Model with GRPO

This repository hosts a custom-built reasoning model powered by **LLama 3.1 8B** and enhanced using **GRPO (Guided Reinforcement with Preference Optimization)**. The model is fine-tuned for advanced reasoning tasks, designed to perform logical inference, multi-step deduction, and structured decision-making.

## 🔍 Key Features

- **LLama 3.1 Backbone**: Utilizes the power of Meta’s LLama 3.1 for high-quality language understanding.
- **GRPO Training**: Reinforcement-based preference optimization to guide reasoning performance.
- **Enhanced Reasoning**: Optimized for complex prompts, chain-of-thought reasoning, and preference-aligned outputs.

## 📦 Contents

- `model/` — Model weights and configs (or links)
- `training/` — Scripts and GRPO config used for training
- `inference/` — Quick inference code and usage samples
- `examples/` — Reasoning test prompts and outputs

## 🚀 Usage

- Run the python script..
